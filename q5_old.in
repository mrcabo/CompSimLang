set INPUT 30
set HIDDEN 15
set OUTPUTS 30

#make sure you are in the correct directory
#cd C:/research/Babble-A-Lex/model/Lens/BabbleLex

# creates and activates new network
# SRBPTT (simple recurrent backprop-through-time)
# Don't need to use CONTINUOUS (fully recurrent)
addNet myNet -i 864 SRBPTT $INPUT $HIDDEN ELMAN $OUTPUTS

#add a lexicon layer
#addGroup labels 5 OUTPUT
#connectGroups hidden labels

# order the groups
orderGroups bias input context hidden output

# Randomizes weights from +/- .1
randWeights -r 0.1

# load examples: statistical learning based on prediction
loadExamples q5_train.ex
# loadExamples q5_train.ex -s q5train -exmode ORDERED -m R
# useTrainingSet q5train 
# useTestingSet q5train 

graphObject

#saveWeights preTrain.wt


setObj learningRate 	0.1
setObj momentum 	0.8

setObj batchSize        1
dougsMomentum 3888 -r 100

#setObj batchSize        0
#dougsMomentum 500 -r 10

#50 training cycles is too few here
#test statistical learning
# set f [open "q5Learned.txt" "a"]
# puts $f [test -r]
#close $f

# saveWeights postTrain.wt